{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e3cadb",
   "metadata": {},
   "source": [
    "# üìä Stock Performance Data Collection with yFinance\n",
    "\n",
    "This notebook collects historical stock price data for selected S&P 500 companies using the **yfinance** API.\n",
    "The goal is to build a clean, structured dataset that can later be used for:\n",
    "- Financial analysis\n",
    "- Visualization in Excel or Tableau\n",
    "- Return and volatility calculations\n",
    "- Event-based analysis\n",
    "\n",
    "**Time period:** January 1, 2025 to July 1, 2025  (First Half of 2025)\n",
    "**Sectors covered:** Technology and Banking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b03c9",
   "metadata": {},
   "source": [
    "I used:\n",
    "- **yfinance** to fetch stock market data  \n",
    "- **pandas** for data manipulation  \n",
    "- **datetime** to define the date range dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff439258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac2176",
   "metadata": {},
   "source": [
    "Each ticker represents a publicly traded firm.\n",
    "These companies were selected to compare **tech vs financial institutions**.\n",
    "\n",
    "- Apple (AAPL)\n",
    "- NVIDIA (NVDA)\n",
    "- JPMorgan Chase (JPM)\n",
    "- Bank of America (BAC)\n",
    "- Goldman Sachs (GS)\n",
    "- Morgan Stanley (MS)\n",
    "- Citigroup (C)\n",
    "- Wells Fargo (WFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6674c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AAPL', 'NVDA', 'JPM', 'BAC', 'GS', 'MS', 'C', 'WFC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e635062",
   "metadata": {},
   "source": [
    "I then analyzed the **180 trading days** leading up to **July 1, 2025**.\n",
    "This captures recent market behavior while avoiding short-term noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7911a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime(2025, 7, 1)\n",
    "start_date = end_date - timedelta(days=180)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1af6a7",
   "metadata": {},
   "source": [
    "Used a list to temporarily store each stock's DataFrame.\n",
    "Later, all datasets will be combined into a single master table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b5656a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acee0206",
   "metadata": {},
   "source": [
    "\n",
    "For each ticker:\n",
    "- Download historical prices\n",
    "- Reset the index so Date becomes a column\n",
    "- Ensure consistent column structure\n",
    "- Add a Ticker column for identification\n",
    "\n",
    "This step prevents downstream issues during visualization or analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad16bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded data for AAPL\n",
      "‚úÖ Downloaded data for NVDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded data for JPM\n",
      "‚úÖ Downloaded data for BAC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded data for GS\n",
      "‚úÖ Downloaded data for MS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Downloaded data for C\n",
      "‚úÖ Downloaded data for WFC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        data = yf.download(\n",
    "            ticker,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            auto_adjust=True\n",
    "        )\n",
    "\n",
    "        data['Ticker'] = ticker\n",
    "        data.reset_index(inplace=True)\n",
    "\n",
    "        if 'Adj Close' not in data.columns:\n",
    "            data['Adj Close'] = data['Close']\n",
    "\n",
    "        required_columns = [\n",
    "            'Date', 'Open', 'High', 'Low',\n",
    "            'Close', 'Adj Close', 'Volume', 'Ticker'\n",
    "        ]\n",
    "\n",
    "        for col in required_columns:\n",
    "            if col not in data.columns:\n",
    "                if col == 'Adj Close':\n",
    "                    data[col] = data['Close']\n",
    "                else:\n",
    "                    data[col] = 0\n",
    "\n",
    "        data = data[required_columns]\n",
    "        all_data_list.append(data)\n",
    "\n",
    "        print(f\"‚úÖ Downloaded data for {ticker}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading {ticker}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f5b20",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "All individual stock tables are merged into a single DataFrame.\n",
    "This format is ideal for:\n",
    "- Tableau dashboards\n",
    "- Excel pivot tables\n",
    "- Python-based analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6baded45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: [('Date', ''), ('Open', 'AAPL'), ('High', 'AAPL'), ('Low', 'AAPL'), ('Close', 'AAPL'), ('Adj Close', ''), ('Volume', 'AAPL'), ('Ticker', ''), ('Open', 'NVDA'), ('High', 'NVDA'), ('Low', 'NVDA'), ('Close', 'NVDA'), ('Volume', 'NVDA'), ('Open', 'JPM'), ('High', 'JPM'), ('Low', 'JPM'), ('Close', 'JPM'), ('Volume', 'JPM'), ('Open', 'BAC'), ('High', 'BAC'), ('Low', 'BAC'), ('Close', 'BAC'), ('Volume', 'BAC'), ('Open', 'GS'), ('High', 'GS'), ('Low', 'GS'), ('Close', 'GS'), ('Volume', 'GS'), ('Open', 'MS'), ('High', 'MS'), ('Low', 'MS'), ('Close', 'MS'), ('Volume', 'MS'), ('Open', 'C'), ('High', 'C'), ('Low', 'C'), ('Close', 'C'), ('Volume', 'C'), ('Open', 'WFC'), ('High', 'WFC'), ('Low', 'WFC'), ('Close', 'WFC'), ('Volume', 'WFC')]\n",
      "Data shape: (976, 43)\n",
      "‚úÖ Data saved to stock_data_raw.xlsx\n",
      "Total rows: 976\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if all_data_list:\n",
    "    all_data = pd.concat(all_data_list, ignore_index=True)\n",
    "\n",
    "    print(\"Columns:\", all_data.columns.tolist())\n",
    "    print(\"Data shape:\", all_data.shape)\n",
    "\n",
    "    if isinstance(all_data.columns, pd.MultiIndex):\n",
    "        all_data.columns = [\n",
    "            col[0] if col[1] == '' else f\"{col[0]}_{col[1]}\"\n",
    "            for col in all_data.columns\n",
    "        ]\n",
    "\n",
    "    all_data.to_excel('stock_data_raw.xlsx', index=False)\n",
    "\n",
    "    print(\"‚úÖ Data saved to stock_data_raw.xlsx\")\n",
    "    print(\"Total rows:\", len(all_data))\n",
    "else:\n",
    "    print(\"‚ùå No data downloaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40385e44",
   "metadata": {},
   "source": [
    "\n",
    "## üì• Importing Cleaned Excel Data into Python\n",
    "\n",
    "After exporting the raw stock data to Excel, I used **Power Query Editor** to:\n",
    "- Remove inconsistencies\n",
    "- Standardize column names\n",
    "- Validate missing values\n",
    "- Prepare the dataset for analysis and visualization\n",
    "\n",
    "This section imports the cleaned Excel file back into Python for validation\n",
    "and additional calculations before visualization.\n",
    "\n",
    "The Excel file is stored locally in the same project directory.\n",
    "Using pandas, the cleaned dataset is loaded into a DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b458cd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume Traded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>248.330961</td>\n",
       "      <td>248.500565</td>\n",
       "      <td>241.238085</td>\n",
       "      <td>243.263199</td>\n",
       "      <td>243.263199</td>\n",
       "      <td>55740700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>BAC</td>\n",
       "      <td>43.606222</td>\n",
       "      <td>44.050781</td>\n",
       "      <td>43.270334</td>\n",
       "      <td>43.754410</td>\n",
       "      <td>43.754410</td>\n",
       "      <td>25610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>C</td>\n",
       "      <td>69.893242</td>\n",
       "      <td>70.109997</td>\n",
       "      <td>68.622275</td>\n",
       "      <td>68.907997</td>\n",
       "      <td>68.907997</td>\n",
       "      <td>9827400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>GS</td>\n",
       "      <td>573.592419</td>\n",
       "      <td>578.543071</td>\n",
       "      <td>564.116865</td>\n",
       "      <td>569.295227</td>\n",
       "      <td>569.295227</td>\n",
       "      <td>2219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>JPM</td>\n",
       "      <td>237.072695</td>\n",
       "      <td>239.395009</td>\n",
       "      <td>235.626169</td>\n",
       "      <td>236.167389</td>\n",
       "      <td>236.167389</td>\n",
       "      <td>9220900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Ticker        Open        High         Low       Close  \\\n",
       "0 2025-01-02   AAPL  248.330961  248.500565  241.238085  243.263199   \n",
       "1 2025-01-02    BAC   43.606222   44.050781   43.270334   43.754410   \n",
       "2 2025-01-02      C   69.893242   70.109997   68.622275   68.907997   \n",
       "3 2025-01-02     GS  573.592419  578.543071  564.116865  569.295227   \n",
       "4 2025-01-02    JPM  237.072695  239.395009  235.626169  236.167389   \n",
       "\n",
       "    Adj Close  Volume Traded  \n",
       "0  243.263199       55740700  \n",
       "1   43.754410       25610600  \n",
       "2   68.907997        9827400  \n",
       "3  569.295227        2219000  \n",
       "4  236.167389        9220900  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"stock_data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0624046",
   "metadata": {},
   "source": [
    "After cleaning and structuring the raw stock price data in Excel, we proceed with exploratory analysis and visualization in Python using Matplotlib. This step helps us understand price movements, volatility, trading activity, and overall performance of each stock over the past six months. The cleaned dataset has been added to the GitHub repository to ensure reproducibility and version control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cdf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
